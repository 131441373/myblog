针对 多个object的location

如: 给定一个你关注的object集合, 然后将图上所有你关注的object框起来 (如天空/草这些背景就不关注了

下文中记 bbox = bounding box (最小外接矩形)




### R-CNN (region)
使用SS(selective search)选定约2k的矩形区域RoI(religion of interest)
然后每个区域跑SVM 和 bbox regression

问题一: SS正确率感人
问题二: 2k个RoI很可能有重复性, 独立的提取特征有太多的运算重复

### Fast R-CNN
针对问题二: 将特征提取直接在原图上进行, 这样CNN只用跑一次 ( R-CNN没有这么做也可能是当时没有RoI Pooling, 图片的resize在bp时不能求导

仍然在原图上SS, 然后将RoI区域通过CNN各层的shape**映射**到CNN输出层上的一个区域

即: 将CNN与SS解耦了

### Anchor设计
固定面积, 设置ratio = 1, 0.5, 2
使得在固定面积的情况下, 长宽比为ratio
(固定面积相对固定短边的优势: 框更丰富)

#### Anchor用于训练

$n_a$个anchor 和 $n_b$ 个 gt(ground true), $n_a\ge n_b$
按照如下规则匹配

1.
定义 $X_{i,j} = IoU(anchor_i, gt_j)$
![](https://d2l.ai/_images/iou.svg)
每次取出X中的最大元素, 将该格对应anchor和gt匹配, 然后删除X的该行和该列
这样一直操作下去, 最后每个gt都会匹配一个anchor, 然后剩下一些anchor

2.
这些剩下的anchor, 找其IoU最大的gt, 如果IoU值超过某个threshold, 则将其与gt匹配, 否则将其标记为background

对于匹配了gt的anchor
定义其offset(偏差)为

$$\left( \frac{ \frac{x_b - x_a}{w_a} - \mu_x }{\sigma_x}, \frac{ \frac{y_b - y_a}{h_a} - \mu_y }{\sigma_y}, \frac{ \log \frac{w_b}{w_a} - \mu_w }{\sigma_w}, \frac{ \log \frac{h_b}{h_a} - \mu_h }{\sigma_h}\right)$$

3.
负样本(分配为背景的样本可能过多, 导致NN过于重视区分负样的的分类
需要用 难例发掘 优化一下:
即将负样本按照loss从高到低排序(loss高即大概率认为是object), 从高loss的开始取使得 正负样本比约 1:3
(难分辨得解决了简单分辨的一般就不成问题)

默认值 $\mu_x = \mu_y = \mu_w = \mu_h = 0, \sigma_x=\sigma_y=0.1, and, \sigma_w=\sigma_h=0.2$

#### Anchor用于预测
不同的anchor加上offset后得到的predicted bbox可能非常相近, 这在预测的时候显得多余
于是要用的NSM技术(non-maximum suppression)(非极大值抑制: 抑制非极大值)

方法是每次取出置信度(概率)最高的predicted bbox, 然后将与之IoU大于某个阈值(0.3~0.5的超参数)的predicted bbox删掉

不难发现这种做法有个漏洞: 重合的框可能是两个object
举个例子: 一群人拍毕业照, 很可能一个人的半个身子被另一个人挡住, 然后两个框就显得非常相近

soft-nsm进行了一些调整:
nsm的删除可以理解为将p设为0, 即
$p_i =\left ( \begin{matrix} p_i & IoU(M, box_i) < t \\0& else \end{matrix} \right. $
而在soft-nsm中, 而是调整分数, 但不删除
有两种方式:
线性的:
$p_i =\left ( \begin{matrix} p_i & IoU(M, box_i) < t \\ p_i (1 - IoU)& else \end{matrix} \right. $
非线性的:
$p_i =p_i e^{\frac {-IoU^2}{\sigma}} $

### Faster R-CNN
针对问题一: 将SS换成RPN(region proposal network
其提出的 RoI 量少质优

首先仍如Fast R-CNN, 先跑一个CNN得到feature map
然后对feature map上的任意一个pixel加9个anchor
![如图](https://picb.zhimg.com/80/v2-7abead97efcc46a3ee5b030a2151643f_1440w.jpg)
首先我们要训练RPN, 这样构造其训练集
如果anchor还原到原图后, 与某个


最后, 留下的所有anchor中, p>某个阈值的才作为结果

### SSD
single shot detection
![如图](https://pic2.zhimg.com/v2-07eda75a3c5119defb2a13f7f6fe6817_b.jpg)
![如图](https://pic3.zhimg.com/80/v2-6e73f4f987013d933744bf70045b3aa8_1440w.jpg)

https://zhuanlan.zhihu.com/p/79854543

核心思想就是: 多尺度检测, 将CNN划分成若干部分, 每个部分的output都跑一下检测
越靠近图片的层, 用于检测越小的东西

### YOLO v3
主干线也是SSD那样 多尺度
下图中, 图片的尺寸256*256不是关键信息, 可忽略或自行调整大小
![如图](https://pic1.zhimg.com/80/v2-d2596ea39974bcde176d1cf4dc99705e_1440w.jpg)


### R-FCN

### SSD模板
