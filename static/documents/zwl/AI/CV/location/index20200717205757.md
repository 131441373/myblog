针对 单一object 的定位

如: 除了知道图片的主体是一只猫, 还希望有个框框出来它在哪
进阶如: 给出一个人, 希望用14个点描绘出人的大致框架( 头, 脖子, 双肩, 双手腕, 双手, 双腰, 双膝盖, 双脚)

### 将其视为regression问题
即在classification 的CNN结束后
既跑类别分类器, 也跑一个区域猜测( 如训练返回4元组 (x0, y0, width, height)) (如上面进阶问题则跑 14个猜测网络, 每个网络返回一个二元组)

然后代价变成 分类器的loss + location的loss (**必要时使用加权和**)

虽然这样两个loss一起跑一起训练, 感觉怪怪的
但是就是一定程度上ok, 玄学

另一种想法是:
能不能先训练出CNN, 把他fix住, 然后剩下的两个分开练
也行
但是有时训练的特征并不是所有任务通用的
所以将 任务 和 提取特征 的网络叠加在一起同时训练, 能更有任务上的针对性

### 模板
Face Landmarks(标记眼睛,鼻子,嘴巴
CelebA数据集

```python
import os
import torch
import torch.nn as nn
import torch.utils.data as Data
import torchvision
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image

def apply_cuda(x):
    if torch.cuda.is_available():
        if hasattr(x, '__iter__'):
            return tuple(map(lambda x: x.cuda(), x))
        else:
            return x.cuda()
    else:
        return x

class CelebA_Dataset(Data.Dataset):
    def __init__(self):
        self.transform = torchvision.transforms.Compose([
            torchvision.transforms.ToTensor()   
        ])
        self.bbox = pd.read_csv("../input/celeba-dataset/list_landmarks_align_celeba.csv")
    
    def __len__(self):
        return 162770
    
    def __getitem__(self, idx):
        name = "{}.jpg".format("%06d" % (idx + 1))
        img = Image.open("../input/celeba-dataset/img_align_celeba/img_align_celeba/" + name)
        img = self.transform(img)
        box = torch.Tensor(self.bbox.iloc[idx].drop(labels="image_id").tolist())
        return apply_cuda((img, box))
       
    
loader = Data.DataLoader(
    dataset = CelebA_Dataset(),
    shuffle = True,
    batch_size = 20
)

class Net(nn.Module):
    def __init__(self):
        super().__init__()
        resnet = torchvision.models.resnet18()
        self.CNN = nn.Sequential(
            resnet.conv1,
            resnet.bn1,
            resnet.relu,
            resnet.maxpool,
            resnet.layer1,
            resnet.layer2,
            resnet.layer3,
            resnet.layer4,
            resnet.avgpool,
            nn.Flatten(), 
        ) # -> 512 length
        self.POSs = nn.Linear(512, 10)
        
    def forward(self, x):
        x = self.CNN(x)
        x = self.POSs(x)
        return x

model = apply_cuda(Net())
params_path = '/kaggle/working/params.ckpt'
if os.path.exists(params_path):
    model.load_state_dict(torch.load(params_path))
    
optim = torch.optim.Adam(model.parameters(), weight_decay = 0.01)
criter = nn.MSELoss()

losy = []
plt.ion()
for epoch in range(10):
    lsum = 0
    tot = 0
    for x, y in loader:
        pre = model(x)
        loss = criter(pre, y)
        lsum += loss
        optim.zero_grad()
        loss.backward()
        optim.step()
        
        tot += 20
        if (tot % 1000 == 0):
            print("epoch{}: {} / {}, lsum = {}".format(epoch, tot, 162770, lsum), end='\r')
    losy.append(lsum)
    plt.cla()
    plt.plot(list(range(epoch+1)), losy, marker='x')
    plt.pause(1)
    torch.save(model.state_dict(), params_path)
    
plt.ioff()
plt.show()
```

test用代码
```python
is_testing = True
if is_testing:
    bbox = pd.read_csv("../input/celeba-dataset/list_landmarks_align_celeba.csv")
    transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])

    idx = 10
    name = "{}.jpg".format("%06d" % (idx + 1))
    img = Image.open("../input/celeba-dataset/img_align_celeba/img_align_celeba/" + name)
    plt.imshow(img)
    img = torch.Tensor([transform(img).numpy()])
    box = bbox.iloc[idx].drop(labels="image_id").tolist()

    model = Net()
    params_path = '/kaggle/working/params.ckpt'
    if os.path.exists(params_path):
        model.load_state_dict(torch.load(params_path))
    mox = model(img).detach().numpy().reshape((10))

    plt.scatter([box[0], box[2], box[4], box[6], box[8]],[box[1], box[3], box[5], box[7], box[9]], marker='o', c = 'b')
    plt.scatter([mox[0], mox[2], mox[4], mox[6], mox[8]],[mox[1], mox[3], mox[5], mox[7], mox[9]], marker='x', c = 'r')
    plt.show()
```