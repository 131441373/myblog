https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf

# 原理
对于H*W的图象, 可以视为一个 H*W维空间中的一个点, 其中每个维度的范围为 0~1
真实的图象在其中 x有一个distribution: $P_{data}$ (真实图象可能集中分布在若干集中的几何空间
我们不知道distribution的数学表达, 我们可以sample它, 但是不知道它具体的数学form



# 模板
注意不是死练D, 然后死练G, 然后死练D
而是 两三个batch的D, 接一两个batch的G, 这样渐进
(不然感觉出现overfit, 反正效果不好)


生成二次元头像模板
```
# %% [code]
from pathlib import Path
import torch
import torch.nn as nn
import torch.utils.data as Data
import torchvision
import matplotlib.pyplot as plt
from PIL import Image as PIL
import numpy as np


def apply_cuda(*args):
    if torch.cuda.is_available():
        args = tuple(map(lambda x: x.cuda(), args))
    return args if len(args) > 1 else args[0]


def frozen(net, kd):
    grad = not kd
    for p in net.parameters():
        p.requires_grad = grad

# %% [code]
DatasetBase = Path('/kaggle/input/acg-dataset')
ParamBase = Path('/kaggle/input/gan-acg')
# ParamBase = Path('/kaggle/working/')
WorkingBase = Path('/kaggle/working/')

Config = {
    'batch_size': 20,
    'D_times': 3, # 每次迭代, D训练几次
    'G_times': 1, # 每次迭代, G训练几次
    'frozen_resnet': True, # 训练D时识别器resnet部分是否冻结
    'iter': 100000, # 设为无穷大, 看到差不多就按停就好
    'lr': 2e-4,
    'betas': (0.5, 0.999),
}

# %% [markdown]
# ## Network

# %% [code]
class Reshaper(nn.Module):
    def __init__(self, shape):
        super().__init__()
        self.shape = shape

    def forward(self, x):
        return x.reshape(self.shape)


class Discriminator(nn.Module):
    
    def __init__(self):
        super().__init__()

        self.model = torchvision.models.resnet34(pretrained=True)
        self.model.fc = nn.Flatten()
        
        self.cls = nn.Sequential(
            nn.Linear(512, 128),
            nn.LeakyReLU(0.2),
            nn.Linear(128, 128),
            nn.LeakyReLU(0.2),
            nn.Linear(128, 1),
            nn.Sigmoid(),
        )

    def forward(self, img):
        return self.cls(self.model(img))


class Generator(nn.Module):
    def make_block(self, in_channels, out_channels, norm=True):
        # 以下代码从下往上逆着写
        layers = [
            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1),
        ]
        if norm:
            layers += [
                nn.BatchNorm2d(out_channels),
                nn.LeakyReLU(0.2),
            ]
        return nn.Sequential(*layers)

    def __init__(self):
        super().__init__()

        # 以下代码从下往上逆着写
        self.layers = nn.Sequential(
            nn.Linear(100, 512 * 4 * 4),
            nn.LeakyReLU(0.2),
            Reshaper((-1, 512, 4, 4)),  # 512 * 4 * 4
            self.make_block(512, 256),  # 256 * 8 * 8
            self.make_block(256, 128), # 128 * 16 * 16
            self.make_block(128, 64),  # 64 * 32 * 32
            self.make_block(64, 3, norm=False), # 3 * 64 * 64
            nn.Tanh(), # 转为-1~1范围
        )

    def forward(self, x):
        return self.layers(x)

# %% [markdown]
# ## Data Loader

# %% [code]
class ACG_Realer():
    def __init__(self):
        imgList = []
        for f in (DatasetBase / 'images').iterdir():
            imgList.append(f)

        self.transform = torchvision.transforms.Compose([
            torchvision.transforms.ToTensor(),
            torchvision.transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),
            # [0,1] -0.5->[-0.5,0.5] /0.5-> [-1,1]
        ])

        self.imgList = []  # 先读进来, 否则太慢
        for path in imgList:
            self.imgList.append(self.transform(PIL.open(path)))
        self.imgList = torch.stack(self.imgList, dim=0)
    
    def __call__(self):
        return apply_cuda(self.imgList[np.random.choice(len(self.imgList), Config["batch_size"])])

# %% [code]
real_sampler = ACG_Realer()    

def fake_sampler(G):
    noise = apply_cuda(torch.randn((Config["batch_size"], 100)))
    return G(noise)

# %% [markdown]
# ## show current result for visualize

# %% [code]
def visualize():
    G = apply_cuda(Generator())
    G_params = WorkingBase / "G_params.ckpt"
    if G_params.exists(): G.load_state_dict(torch.load(G_params))

    tensor2img = torchvision.transforms.ToPILImage()
    denormalize = lambda x : (x + 1) / 2

    G = G.eval()
    with torch.no_grad():
        fake = fake_sampler(G)
        _, axs = plt.subplots(4, 5, figsize=(8, 8))
        for i in range(4):
            for j in range(5):
                axs[i][j].imshow(tensor2img(denormalize(fake[i * 5 + j].cpu())))
                axs[i][j].axis('off')
    plt.show()

#     for real in real_loader:
#         _, axs = plt.subplots(4, 5, figsize=(8, 8))
#         for i in range(4):
#             for j in range(5):
#                 axs[i][j].imshow(tensor2img(real[i * 5 + j].cpu()))
#                 axs[i][j].axis('off')
#         break
        
#     plt.show()

# %% [code]
class Criter(nn.Module):
    def __init__(self):
        super().__init__()
        self.zeros = apply_cuda(torch.Tensor([[0]] * Config["batch_size"]))
        self.ones = apply_cuda(torch.Tensor([[1]] * Config["batch_size"]))
        self.criter = nn.BCELoss()

    def forward(self, x, kd):
        if kd == 1:
            return self.criter(x, self.ones)
        else:
            return self.criter(x, self.zeros)

# %% [markdown]
# ## Main

# %% [code]
if True:
    D = apply_cuda(Discriminator())
    G = apply_cuda(Generator())

    D_params = ParamBase / "D_params.ckpt"
    G_params = ParamBase / "G_params.ckpt"
    D_saves = WorkingBase / "D_params.ckpt"
    G_saves = WorkingBase / "G_params.ckpt"
    if True:
        if D_params.exists(): D.load_state_dict(torch.load(D_params))
        if G_params.exists(): G.load_state_dict(torch.load(G_params))

    D_optim = torch.optim.Adam(D.parameters(), lr=Config["lr"], betas=Config["betas"])
    G_optim = torch.optim.Adam(G.parameters(), lr=Config["lr"], betas=Config["betas"])
    criter = Criter()

    print("start")
    for iter in range(Config["iter"]):
        lsum_D = 0
        lsum_G = 0

        # ---------- train Discriminator ----------
        frozen(G, True)
        frozen(D, False)
        for p in D.model.parameters():
            p.requires_grad = Config['frozen_resnet']

        for time in range(Config["D_times"]):
            real = real_sampler()
            fake = fake_sampler(G)
            p_real = D(real)
            p_fake = D(fake)

            loss = criter(p_real, 1) + criter(p_fake, 0)
            D_optim.zero_grad()
            loss.backward()
            D_optim.step()
            lsum_D += loss.item()

        # ---------- train Generator ----------
        frozen(G, False)
        frozen(D, True)

        for time in range(Config["G_times"]):
            fake = fake_sampler(G)
            p_fake = D(fake)
            loss = criter(p_fake, 1)
            G_optim.zero_grad()
            loss.backward()
            G_optim.step()
            lsum_G += loss.item()

        # ---------- show info ----------
        print(f'\riter{iter}: loss_D: {lsum_D}, loss_G: {lsum_G}', end='')

        if iter % 500 == 0:
            # 保存网络
            torch.save(D.state_dict(), D_saves)
            torch.save(G.state_dict(), G_saves)
            # 并visualize一下当前效果
            visualize()
```

# 一些问题:train不动
[通过一系列复杂推导](https://zhuanlan.zhihu.com/p/54096381) GAN其实是在使 $P_{data}$ 和 $P_{G}$ 的JS散度相同
$M={P+Q\over 2}$, $JS = {KL(P, M) + KL(Q, M)\over 2}$ 缺点是P,Q无overlap时JS是常数优化不下去
而这种情况挺常见的

比如discriminator不要train的太好, 否则loss太平, 对于generator来说, 往哪个方向修改都差不多, 不知道该往哪个方向学
但是这种"不要train太好" 是一个很难衡量的东西, 具体到GAN训练中就是只能几下几下的交替, 不同的超参数还效果差很远

## LSGAN
Least Square GAN: 为了避免log, 把二分类sigmoid+log loss改为linear+L2 loss, 让两类的值分别接近-1和1
Loss Sensitive GAN: linear后用margin loss使两类的值小于margin

## WGAN
希望JS散度改为wasserstein distance: 两个分布的最小移动距离
经过一通复杂推导, 可以通过这样的discrimination loss实现:

D模型linear输出而不是sigmoid输出
目标是使 $E_{x\sim P_{data}} D[x] - E_{x\sim P_G} D[x]$ 尽量大, 对生成器则 $E_{x\sim P_G} D[x]$ 尽量大
模型就让上面这些值的负数作为loss让他们尽量小就可以(小到负也没关系)

但是D不能太离谱, 其需要满足lipschitz限制, 即存在 $K>0$ 使得 $|D(x_1)-D(x_2)| < K||x_1-x_2||$ (等价于梯度<K)
这里作者做法是近似限制: 设置一个很小的 $c=0.01$, 每次step后把模型D的参数都clip在 $(-c, +c)$

WGAN-GP的优化: $loss+\lambda E_{x\sim P_{penalty}} [\max (\nabla_x D(x)-1, 0)]$ 直接采样去对gradient限制使其小于1
其中penalty的生成方式: 从data采样一个点, gen出来的一个点, 两点连线线段中随机一个点 (之后也有工作发现只在data的地方采样更好)
实际implement发现 $\max (\nabla_x D(x)-1, 0)$ 改为 $(\nabla_x D(x)-1)^2$ 更好

Spectrum Norm论文提出一种完全限制gradient<1的方法

## EBGAN
用autoencoder当D, 要求data的MSE小, gen的MSE大, 两者有一个margin
这个D可以pretrain
之后 $L_D(data, g) = D(data) + max(0, m-D(g))$, $L_G = D(g)$