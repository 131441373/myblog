
## Embedding
`nn.Embedding(num_words, dim_embedding)`
其实参数就是一个矩阵num_words * dim_embedding

input是一个LongTensor, 表示单词的在V中的index
比如index是1, 那么他就会矩阵参数中第i行

Embedding会处理的是 dim=-1维, 也即可以接受句子, 也可以接受单个单词

其他参数
max_norm 设置嵌入向量的norm上限


## nn.Conv Maxpool系列 1d版
在处理CV时, 从照片的正上方往下看, 
是一个二维的平面, 依次排布者各个像素
把每个像素看穿, 是一个 (r, g, b) 的三层信息
filter是一个(w*h)的窗口, 在平面上两个方向移动

在处理语言模型时, 从句子的正上方往下看,
是一个时间轴, 依次排布着句子中的单词
把每个词看穿, 是 词嵌入维度 那么深的信息
filter是一个(1*)k的区间, 在时间轴上一个方向移动

**输入维度为 (batch, num_tokens, time)**

**正式开始**
in_channel就是厚度
out_channel就是filter数
kernel_size就是上面说的k

## RNN - LSTM - GRU
`nn.xxx()`
input_size 输入wordvec的维度
hidden_size 模型对应隐藏层的维度
num_layers 对应multilayer版本 (默认1)
batch_first **必须设置成True** 才能pytorch正常用 (batch, length, tokens)
bidirectional	如果 True , 将会变成一个双向 RNN, 默认为 False
dropout 提供概率, 默认0

RNN 和 GRU 是 `output, ht = xxx(X, h0)`
LSTM  `output, (ht, ct) = xxx(X, (h0, c0))`
**其中 h0, c0 这些全0初始化非常主流, 如果用这种, 传参就传X即可** [ref](https://discuss.pytorch.org/t/initialization-of-first-hidden-state-in-lstm-and-truncated-bptt/58384)
其他初始状态todo

output shape (batch, seq_length, hidden_size*num_directions)
h/c shape (num_directions, batch, hidden_size)  # 方向维度在前是合理的, 因为两个方向跑RNN是独立的

## TimeDistribution
keras有个TimeDistribution针对 序列跑出若干结果, 分别通过 **同样参数** 的网络
如果只是要 Linear, 需要怎么样的矩阵就正常写就好 `(batch, length, input_dim) -> (batch, length, output_dim)`
RNN, LSTM, GRU, Embedding, Conv, Maxpool都有这样的效果, 他们的传参都不需要序列长度的
