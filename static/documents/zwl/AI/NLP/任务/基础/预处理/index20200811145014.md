```
# %% [code]
import pandas as pd
import nltk
import re
import spacy
import numpy as np

# %% [markdown]
# ## Preporcess

# %% [code]
df = pd.read_csv("../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv")

# %% [code]
class Filter: # 句号后无空格的写法todo
    def __init__(self):
        patterns = [  # 无关信息的筛除
            (r'<br />', ' '), # imdb数据集里观察得到的莫名符号 (换为空格而非删掉, 否则出现 句号后无空格 难以分句
        ]
        self.patterns = [(re.compile(regex), replace) for (regex, replace) in patterns]

    def __call__(self, doc):
        for (regex, replace) in self.patterns:
            doc = regex.sub(replace, doc)
        return doc

class Normalizer:
    def __call__(self, doc):
        return [t.lemma_ for t in doc if not (t.is_space | t.is_punct | t.is_stop)]

class Preprocessor:
    def __init__(self):
        self.filter = Filter()
        self.normalizer = Normalizer()
        self.nlp = spacy.load('en', disable=['parser', 'ner']) # 去掉用不到的
        self.nlp.add_pipe(self.normalizer, name='normalize', last=True)
        # print(self.tokenizer.pipe_names)
        # 已有pipe ['tagger', 'parser', 'ner'] -> ['tagger', 'normalize']
        
    def __call__(self, docs):
        docs = [self.filter(doc) for doc in docs]
        docs = list(self.nlp.pipe(docs))
        return docs
    
preprocessor = Preprocessor()

# %% [code]
sentiments = df['sentiment'].apply(lambda sentiment: 1 if sentiment=='positive' else 0)

# %% [code]
docs = df['review'].values.tolist()
tokens = preprocessor(docs)

# %% [code]
a = np.array(tokens)
np.save("tokens.npy", a)
```