PGM

朴素贝叶斯(Naive Bayes) -序列化-> 隐马尔可夫模型(HMMs)　-图化-> 生成式有向图模型
|
逻辑回归(Logistic regression) -序列化-> 线性链式条件随机场(Linear-Chain CRFs) -图化-> 通用条件随机场(General CRFs)

### 贝叶斯网络
一个DAG
对于无入度节点, 其T/F的概率直接给定
对于indeg=k的节点, 其T/F的概率由入边节点的T/F状态决定, 即入边节点的$2^k$个状态每个状态都有一个当前节点的T/F概率分布

此时, 如果要计算所有节点满足某一TF状态的概率, 如 P(H=T, S, N)
就枚举S, N的状态, 然后
用topu结构, 无入度点直接乘概率, 其他点乘其来自入边条件概率

人工构造及其困难

### 马尔可夫模型
与语言模型类似, 也是一个状态概率与前面有关
在假设只与之前的n个有关则称为 n阶马尔科夫链 (n阶马尔科夫链对应n+1元语法)

对于状态转移矩阵, 由于出边(包括自环)总概率必为1, 所以必有每行的和为1, 称为马尔可夫矩阵

对于一阶markov, 可以直接在马尔可夫模型的图上面跑, 跑过的路径的概率乘积, 即为该sentense的概率

### 隐马尔可夫模型
#### definition
这是一种生成式模型,  由果, 猜因
举例说明:
（1）小明所在城市的天气有{晴天，阴天，雨天}三种情况，小明每天的活动有{宅，打球}两种选项。
（2）作为小明的朋友，我们只知道他每天参与了什么活动，而不知道他所在城市的天气是什么样的。
（3）这个城市每天的天气情况，会和前一天的天气情况有点关系。譬如说，如果前一天是晴天，那么后一天是晴天的概率，就大于后一天是雨天的概率。
（4）小明所在的城市，一年四季的天气情况都差不多。
（5）小明每天会根据当天的天气情况，决定今天进行什么样的活动。
（6）我们想通过小明的活动，猜测他所在城市的天气情况。

由此得出HMM的基本定义：  (与上面对应)
(1)(2) 描述对象。HMM是用于描述由隐藏的状态序列 (N种状态) 和 显性的观测序列 (M种状态) 组合而成的双重随机过程。
(3) 一阶马尔科夫性假设。当前时刻的状态值，仅依赖于前一时刻的状态值，而不依赖于更早时刻的状态值。
(4) 齐次性假设。状态转移概率矩阵与时间无关。即所有时刻共享同一个状态转移矩阵。
(5) 观测独立性假设。当前时刻的观察值，仅依赖于当前时刻的状态值。
(6) 目的。通过可观测到的数据，预测不可观测到的数据。我们想通过小明的活动，猜测他所在城市的天气情况。

初始随机在某一个状态, 概率记为 $\pi_{q_i}$
状态到状态有一个转移矩阵, 概率记为 $a_{ij}$
每个状态对应观测情况的不同概率分布, 概率记为 $b_{ij}$

#### 三大基本问题
记u为HMM模型, O为观测序列, Q为状态序列
(1) 估计问题: 给定u和O,  问该观测序列出现的概率P(O|u)
(2) 序列问题: 给定u和O,  从该观测序列反推出最优的状态序列Q, 即最大化 $P(Q|O,u)$
(3) 训练问题: 给定O, 如何调整u的参数, 使得该模型下观测序列出现概率P(O|u)最大? 

##### 问题一
由于$P(O, Q | u) = P(Q | u) P(O | Q, u)$ 得  (**注意这个形式的概率公式非常常用**)

$$P(O|u) = \sum_Q P(O, Q | u) = \sum_Q \left[\left(\pi_{q_1} \prod_{t=2}^L a_{q_{t-1},q_{t}}\right) \prod_{t=1}^L b_{q_{t}, o_{t}} \right]$$

两个连乘都很有层次性, 这是由定义(3)(5)决定的
因此, 使用动态规划的方式可以很容易的解决, 复杂度 $O(n^2 L)$
可以用前向法dp得 $\alpha_t(i) = P(q_1\cdots q_{t-1}=*, q_t=st_i, O_1, \cdots, O_t | u)$ 
或用　后向(反向)dp法得 $\beta_t(i)$ 同理

##### 问题二
同样一个动规解决的问题 (markov的模型特性就是适合动规)

$P(Q|O, u) = \frac {P(Q, O | u)}{P(O|u)}$
分母已经定死, 要是上式最大, 就最大化 $P(Q, O | u)$ , 只要将第一问中的 $\sum$ 改为 $\argmax$ 即可

令 $\delta_t(i) = max P(q_1 \cdots q_{t-1}=*, q_t=st_i, O_1, \cdots, O_t | u)$
dp同时记录该max是从哪个 $q_{t-1}$ 转移而来即可

(由于实际问题中, 往往不仅是要最右, 还要顺带求前n优,  于是动规的时候也要维护前n优

##### 问题三
随机填 $\pi, a, b$
然后定义 

$$e_t(i, j) = P(q_t = s_i, q_{t+1} | O,u) = \frac {P(q_t = s_i, q_{t+1} , O| u)}{P(O|u)} = \frac {\alpha_t(i) ~ a_{ij} ~ \beta_{t+1}(j)} {P(O|u)}$$

表示在该模型下, 时刻$t$位于状态$s_i$, $t+1$位于$s_j$的概率

记 $\gamma_t(i) = \sum_j e_t(i,j)$ 表示时刻$t$位于$s_i$的概率
于是

$$\pi'_i := P(q_1=s_i | O,u) = \gamma_1(i)$$
$$a'_{ij} := \frac {Q中从s_i转移到s_j的期望次数}{Q中从s_i转移到任意state的期望次数} = \frac {\sum_{t=1}^{L-1}e_t(i,j)}{\sum_{t=1}^{L-1} \gamma_t(i)}$$
$$b'_{ij} := \frac {Q中从s_i观测到o_j的期望次数}{Q中从s_i观测到任意o的期望次数} = \frac {\sum_{t=1}^L \gamma_t(i) [o_t == s_i]}{\sum_{t=1}^L \gamma_t(i)}$$

循环执行上述步骤, 直到收敛

##### 浮点问题
由于上述三个问题均使用大量乘法
精度可能下溢()(越乘越小越乘越小越小越小

对于问题二
由于浮点数只涉及乘法和求max
转为log后为加法和求max
这样子一方面加快运算, 另一方面避免精度下溢

对于问题一三
由于有加法, 不能用上述方法
所以改用成辅助比例系数法, 即所有概率值乘一个系数, 最后再除掉

### 马尔可夫网络 (又称马尔可夫随机场MRF)
贝叶斯网络是有向图DAG, 而马尔可夫网络是无向图, 表示互相影响

马尔科夫性: 一阶马尔科夫链中的只与前一时刻相关, 在MRF中变为只与相邻节点相关
也可以表述为, 对于任意被节点集合C分开的节点集合A和节点集合B,  $P(A, B | C) = P(A | C) P(B | C)$

定义一个子图如果是完全图, 则称为团.  无法再加更多节点称为极大团

如果AB之间有连边, 定义势函数 $\phi[A, B]$ 为一个表, 表示A,B取不同值时的频率
表示仅仅他们两一对在一起的时候, 他们之间的关系 (如 AC很合得来, BD很合得来, CD很合不来,  由此导致AB只能取不同值, 与AB之间的phi表关系不大)

于是对于ABCD环形图,  $P(A, B, C, D) = 1/Z \phi(A, B) \phi(B, C) \phi(C, D) \phi (D, A)$
其中Z为 ABCD在各种状态下,  $\phi(A, B) \phi(B, C) \phi(C, D) \phi (D, A)$ 的频率和, 用于归一化

phi怎么来的不懂todo

### 条件随机场(CRF)
MRF关心联合概率, CRF关心条件概率
例如, 给定一幅图, 划分成很多个小块, 图片信息为观测序列, 希望根据观测, 推测其标签(grass/sky/cow)

在给定观测序列X的条件下,  随机变量Y均只与相邻节点相关
X之间不存在图结构, 只是作为一个条件

todo

### 最大熵原理
todo