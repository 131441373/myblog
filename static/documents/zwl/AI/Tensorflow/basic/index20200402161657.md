## 基本示例
```python
model = keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])
model.compile(optimizer='sgd', loss='mean_squared_error') # 随机梯度下降法， 代价函数

xs = np.array([-1,0,1,2,3,4],dtype='float32') # x set
ys = np.array([-3,-1,1,3,5,7],dtype='float32') # y set

model.fit(xs, ys, epochs=500) # 500次 每个epoch都会输出： 第几次，耗时， 代价函数的值

print(model.predict([10.0])) # 训练后预测
# model.evaluate(x', y') 可看看训练效果bias之类的
```

## 构造神经网络
```python
# 三层
model = keras.Sequential([ # 第0层为读入，0-1,1-2,2-3连接方式为下面定义，所以1的时候要声明input_shape/dim/length
    keras.layers.Flatten(input_shape=(28,28)), # 28*28的图flat成一列
    keras.layers.Dense(128, activation=tf.nn.relu), # 中间层
    keras.layers.Dense(10, activation=tf.nn.softmax) # 10种结果
])
```

## Callback
```python
class myCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        if logs.get('loss') < 0.4:
            self.model.stop_training = True

# ....
model.fit(xs, ys, epochs=500, callbacks=[myCallback()]) # 每次训练完调用callback
```