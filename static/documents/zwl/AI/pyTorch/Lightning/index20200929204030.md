
# Clone Dataset to Content

```
!pip install rarfile
import tarfile
import zipfile
import rarfile
import shutil

def uncompress(src_dir, dest_dir):
    with open(src_dir, 'rb') as src_file:
        file_name, file_type = os.path.splitext(src_dir)
        try:
            if file_type == '.zip':
                # 需要安装zip包：pip install zipp
                zip_file = zipfile.ZipFile(src_file)
                for names in zip_file.namelist():
                    zip_file.extract(names, dest_dir)
                zip_file.close()

            elif file_type == '.rar':
                # 需要安装rar包：pip install rarfile
                rar = rarfile.RarFile(src_file)
                os.chdir(dest_dir)
                rar.extractall()
                rar.close()

            else:
                tar = tarfile.open(fileobj=src_file)
                for name in tar.getnames():
                    tar.extract(name, dest_dir)
                tar.close()

        except Exception as ex: return False
        return True
```

```
drive_location = '/content/drive/My Drive/ML/Dataset/ACG/images.zip'
copy_location = '/content/images.zip'
unzip_location = '/content/Dataset'
```

```
shutil.copyfile(drive_location, copy_location) # 目录则用copytree
uncompress(copy_location, unzip_location)
```

# Download Requirements
```
#!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py
#!python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev
```

```
!pip install pytorch-lightning
```

# Import
```
import os
import pandas as pd
import torch
from torch import nn
import torch.nn.functional as F
from torchvision.datasets import MNIST
import torch.utils.data as Data
from torchvision import transforms
import pytorch_lightning as PL
from pytorch_lightning import Trainer
```

# Model
```
class Classifier(PL.LightningModule):
    def make_block(self, in_channels, out_channels):
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.LeakyReLU(0.1),
            nn.Conv2d(out_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.LeakyReLU(0.1),
            nn.MaxPool2d(2),
        )
        
    def __init__(self, num_classes=10):
        super().__init__()
        self.save_hyperparameters() # 保存init中的传参, 使用见下

        self.layers = nn.Sequential(
            self.make_block(1, 16), # 14 * 14
            self.make_block(16, 32), # 7 * 7
            nn.Flatten(), # 32 * 7 * 7
            nn.Linear(32*7*7, 200), # 200
            nn.LeakyReLU(0.1),
            nn.Linear(200, self.hparams.num_classes), # 这样使用超参数
        )

    def forward(self, x):
        return self.layers(x)

    def training_step(self, batch, batch_idx):
        x, y = batch
        p = self(x)
        loss = F.cross_entropy(p, y)
        return {'loss': loss, 'log': {'train_loss': loss}}

    def validation_step(self, batch, batch_idx):
        x, y = batch
        p = self(x)
        loss = F.cross_entropy(p, y)
        return {'loss':loss, 'val_loss': loss}

    def validation_epoch_end(self, outputs):
        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()
        logs = {'val_loss': avg_loss}
        return {'avg_val_loss': avg_loss, 'log': logs}
    
    def test_step(self, batch, batch_nb):
        x, y = batch
        p = self(x)
        return {'test_loss': F.cross_entropy(p, y)}

    def test_epoch_end(self, outputs):
        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()
        logs = {'test_loss': avg_loss}
        return {'avg_test_loss': avg_loss, 'log': logs, 'progress_bar': logs}

    def configure_optimizers(self):
        return torch.optim.Adam(self.parameters(), lr=1e-3)
    
    def prepare_data(self):
        self.trainSet = MNIST(os.getcwd(), train=True, download=True, transform=transforms.ToTensor())
        self.valSet = MNIST(os.getcwd(), train=True, download=True, transform=transforms.ToTensor())
        self.testSet = MNIST(os.getcwd(), train=False, download=True, transform=transforms.ToTensor())

    def train_dataloader(self):
        return Data.DataLoader(self.trainSet, batch_size=32, shuffle=True, num_workers=4)

    def val_dataloader(self):
        return Data.DataLoader(self.valSet, batch_size=32, num_workers=4) 

    def test_dataloader(self):
        return Data.DataLoader(self.testSet, batch_size=32, num_workers=4)
```

# Main
```
!rm -rf ./lightning_logs/ 
!mkdir ./lightning_logs/
%load_ext tensorboard
%tensorboard --logdir ./lightning_logs/
```

```
PL.seed_everything(0) # 固定随机种子
model = Classifier()

# 可选参数 # gpus=1 # tpu_cores=8
trainer = PL.Trainer(progress_bar_refresh_rate=20, max_epochs=10) # 修改最大轮数

trainer.fit(model)
```