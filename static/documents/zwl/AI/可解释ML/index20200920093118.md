例如对于classicfy, 有两种解释
1. 局部: 对于一张图片, 机器是怎么判断它是猫的
2. 全局: 机器心目中猫是什么样子的

模型审判: 看一下机器学到了什么

## Local Explaination
法一x: 图片中删除某个component, 能够导致判断出错, 那么那个部分很可能就是重要的

法二: 设当前判断为狗, 设最后分类k是狗, 对某个pixel $x_i$做一个小的扰动$\Delta x_i$, 看 $| \frac {\Delta y_k}{\Delta x_i} |$ 即 $|\frac{\partial y_k}{\partial x_i}|$ 判断该pixel与结果的相关度
(一个相对可行的方法, 可能会遇到xy先正相关后放平的情况, 这个时候(x超过正相关阈值的时候), 偏导几乎为0, 但其实相关. (也有论文去解决这个问题
[paper](https://www.bilibili.com/video/BV1dE411u7ua?p=19)

## Global Explaination
法一x: 对于某个分类(softmax或sigmoid归一后), 寻找argmax x, 使得x经过网络后, 得到的该分类值最大, 然后观察x就知道分类器心里该分类长啥样
(很可能大量噪音, 甚至可以用来hack模型

法二: 加一个generator, 改为寻找一个噪音z, 使得 g(z) 分类后该份类值最大
[paper](https://arxiv.org/abs/1612.00005)

