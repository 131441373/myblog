##学习资源
[1.1](https://cn.udacity.com/course/intro-to-machine-learning--ud120) [1.2](https://www.coursera.org/learn/machine-learning)
[2.1](https://www.bilibili.com/video/av15532370/?spm_id_from=333.788.videocard.1) [2.2](https://www.bilibili.com/video/av16144388/?spm_id_from=333.788.videocard.0) [2.3](https://www.bilibili.com/video/av16577449)

##前置
[octave](https://www.cnblogs.com/acha/p/11007688.html)

##学习相关
[link](https://www.cnblogs.com/acha/p/11061633.html)

##定义
Field of study that gives computers the ability to learn without being explicitly programmed
learn from experience E with respect to some task T and some performance measure P
按照给电脑的数据是否给出正确答案（或者说真实完整信息）分类
1)supervise learning （如回归直线）
2)unsupervise learning（如给通信记录让电脑将通讯录的人分成几组，如从两人说话加背景音乐中把三者分开）
按照将输入映射为连续函数还是离散函数分类
1)[regression](https://www.cnblogs.com/acha/p/11028892.html)
2)[classification](https://www.cnblogs.com/acha/p/11028898.html)


##underfit, just right, overfit
underfit 如用直线去拟合曲线状的东西
overfit：如强行用n次多项式去拟合n+1个点，导致图像十分鬼畜明显无法达到预测效果
当feature过多，可能使J特别小，但预测效果却不如意
[regularization](https://www.cnblogs.com/acha/p/11042145.html)

##关于非线性问题
前面提到的算法中，解决非线性问题会增加一个形如$x_1^2, x_2^3, x_1x_2, x_4x_5^2$这类特征
这有一些弊端：
1.比如对于特征两两组合的二次项，如果添加得少，可能underfit，添加得多，可能overfit
2.计算量上，n个特征总共有 $O(n^2)$ 个二次项，$O(n^3)$ 个三次项
引入[neural network](https://www.cnblogs.com/acha/p/11040972.html)