## thread
`#include <thread>`
linux编译需要加`-pthread`选项
### 构建
支持移动，不可拷贝
`thread t1(func, args...) 或 new thread(func, args...)` thread一实例化就会**立刻执行**
func里的参数默认只允许传值，因为传引用的话，可能会导致一些同时访问之类的问题
如果一定要用引用，构造时的参数要用 `std::ref()` 括起来

### 两种模式
`t1.join()` 使其阻塞**主线程**,  但**不**阻塞**其他线程**
`t1.detach()` 派遣，不归我管了，你独立跑吧

如果最终希望派遣，那么可以直接在创建变量那写
```
std::thread([](){}).detach(); （即变量名都不需要了）
```

**join和detach之前，自动都是独立先跑着**
但是这两个还是必选其一，必须要写，否则析构的时候会报错
**注意是有且仅有一次**， 可以用`.joinable()`判断是否可join/detach

下面这个写法：4个线程都在创建时就已经跑着了，而join只会阻塞主线程，不会阻塞其他线程
**所以join应该理解为：等线程跑完** 即wait until finish
```
    for (int i = 0; i < 4; i++)
        threads[i]->join();
```

### this_thread
用this_thread::对所在线程执行进程函数
例如`sleep_for`停止一段时间，`sleep_until`, `yield`宣告进程工作已完成, `get_id`

## mutex 互斥锁
`#include <mutex>`
用于解决访问冲突等问题
不可移动，不可拷贝

### 普通锁
每次只有一个线程能够锁定成功，成功的标志是lock()成功返回
加锁后，任何其他试图再次加锁的线程会被阻塞，直到当前线程解锁
如果没锁成功，那么线程就会阻塞在那里
如果解锁时有一个以上的线程阻塞，那么所有阻塞的线程都会尝试变成就绪状态，第一个变为就绪状态的线程继续执行加锁操作，其他线程继续进入阻塞状态
**临界区就像一间只能反锁的房间，一个线程进入后反锁房间，其他线程只能等待它出来才能进入其中，并再次反锁房间**

使用方式：
访问共享资源之前进行加锁操作
访问完成之后进行解锁操作
```
static std::mutex mu; // static防止其他文件弄，因为线程这种东西，挺多注意事项得
...

{ //某段代码
mu.lock()
// dosomething
mu.unlock()
}
```

尽量少的使用锁， 一种可行的方式为：
先用线程独立的局部变量保存一些结果，然后最后再把这些局部变量一次性更新到公用的地方，这时才加锁


#### 辅助tag类
std::adopt_lock，表示之前已经上锁，只获取管理权
std::defer_lock, 表示不希望构造时立刻上锁，只获取管理权
std::try_lock, 尝试加锁，但是加锁失败不会阻塞

#### 辅助类
`std::lock_guard<std::mutex> locker(mu);` 不可移动不可复制
这种，类包装，构造时lock，析构时解lock，可以解决一些异常后没解锁的问题，或者你自己想return，每次return前都得unlock的问题
就好像指针new出来之后，总是要注意delete，然后c++就提供了智能指针帮你RAII

`std::unique_lock<std::mutex> locker(mu)` 可移动不可复制
提供更多的灵活性, 但是牺牲更多的时间（所以一般还是用lock_guard)
直接(mu)构造不会帮你lock，需要你自己调用lock或在构造时加上try_lock函数
例如提供了`lock()`和`unlock()`
还提供了`try_lock()` 返回值是lock是否成功，失败不会阻塞
类里存了一个_M_own的成员变量，记录当前lock了没有，如果析构时没有手动unlock，他还是会帮你unlock的
`owns_lock()`可以获取`_M_own`, 用来判断lock了没有，例如在try_lock构造后或手动调用try_lock后

### 死锁
t1线程先锁mutex1再锁mutex2
t2线程先锁mutex2再锁mutex1
结果导致恰好t1刚锁mutex1 时 t2刚锁mutex2, 然后t1跑不下去，t2也跑不下去，这两个锁也再也解不开了

解决法： 保证mutex顺序相同
解决法2：
```
std::lock(mutex1, mutex2) 这样锁
std::lock_guard<std::mutex> l1(mutex1, std::adopt_lock); //只获取析构权，为了保证析构
std::lock_guard<std::mutex> l1(mutex2, std::adopt_lock); //只获取析构权，为了保证析构
```

## condition variable
线程1： `先unlock`， 然后`cond.notify_one()`或`notify_all()`
线程2：`构造locker`, `cond.wait(locker, 所需条件的lambda函数)` 暂时解开locker，然后阻塞
等待其他线程发来notification， 如果收到时满足了条件就锁上locker，取消阻塞状态

由于需要随时自由的lock和unlock，只能用unique_lock, 不能用lock_guard

##  异步 （更推荐！）
hint：异步（Asynchronous）同步(Synchorous)
主要解决线程里需要一些返回值 或者 进行回调之类的东西
这种方式称`task-based`，更推荐于`thread-base`
`#include <future>`

### future
promise/future 可以用来在线程之间进行简单的数据交互，而不需要考虑锁的问题

#### 构造
一般从 std::async, std::promise::get_future, std::packaged_task::get_future 创建
如果是默认函数构造，或是构造后被别人move去，或是构造后被share去，_M_state（即valid()) 就会是false
只可移动，不可复制

#### future_status
是一个enum class
future_status::ready	设置了值或者发生了异常。
future_status::timeout	 超时
future_status::deferred	共享状态包含了 deferred 函数

#### 成员函数
`.valid()` 判断是否valid
`.get()` 阻塞当前线程，等待共享状态变为ready，并获取值/异常
`.wait()`阻塞当前线程，等待共享状态变为ready，但不获取值/异常
`.wait_for(time)`类似wait，返回值为future_status

#### shared_future
std::shared_future 可以拷贝、移动，多个 std::shared_future 可以共享某个共享状态的最终结果(即共享状态的某个值或者异常)
shared_future 可以通过某个 std::future 对象隐式构造，或者通过 std::future::share() 这个成员函数显示转换
无论哪种转换，被转换的那个 std::future 对象都会变为 not-valid.
可以get()多次

### promise
promise/future 可以用来在线程之间进行简单的数据交互，而不需要考虑锁的问题
只可移动，不可复制

通过promise的接口设置特定值，然后可以继续执行目标线程自身的工作
这与future不同，future只能在结束时有值，promise运行时也可以设置值

#### 承诺（与future绑定
```
std::promise<T> p;
std::future<T> fu = p.get_future();
```
一个promise对象里，存了一个future相关的一个state, 一个T类型的值
get_future会用state构造一个future<T>类， 然后state会被标记为已用，也即，一个promise不能绑定多个future
如果要，那么用shared_future去接收 get_future的值

#### 使用
上文“承诺”处提到的那个state，是个指针，通过这样绑定共享到future中
然后promise中set_value/set_exception就是去state->设置value,  这样所有跟他绑定的future就能够通过这个state去访问了

而set_value其实就跟直接使用future时，函数返回返回值时调用的
所以set_value被限制只能调用一次

绑定的future进行get的时候，就会等待promise来set_value()

#### 应用
主要是主线程set_value给子线程，（在构造thread/async时把绑定的那个future以std::ref()形式传入子线程的函数）
而不是子线程set_value给主线程，这是future就能干的

### async
`std::future<返回值类型> fu = std::async(func, args...);` 其中我们要异步获取func的返回值
当然，这里只是为了具体学习，使用时直接`auto fu = std::async(func, args..)` 即可

可以指定launch policy, 在std::async的参数最开头加个launch的enum class，见下↓

#### 优势
线程管理的任务都交给了C++标准库来管理了。C++标准库负责处理线程过载，负载不均衡等问题

除非遇到以下三种问题：
需要访问底层的线程实现的API，这个时候通过std::thread可以拿到底层线程的句柄，然后才可以使用底层的线程API。
需要给你的应用程序来优化线程的使用，这需要根据应用的特点来优化线程的使用，比如特定机器架构的服务器软件，这个时候就需要使用特定平台下的线程实现。
你需要实现一些高级的线程组件，例如线程池，这是C++标准库没有提供的高级组件

#### launch policy
std::launch是future里的一个enum，其内有async和deferred两类
**默认的policy是 两个policy的或， 可以解决很多问题（见优势处），系统自己决定怎么调用**
launch::async 保证异步行为，执行后，系统创建一个线程执行对应的函数
launch::deffered 表示延迟调用，在调用future中的wait()或者get()函数时，才执行入口函数

**注意，get和wait才会把defer的async激活，wait_for并不**
