`pip3 install requests`


### 基础
get(用text获取html, 如果是图片用content获取二进制形式(保存时用`wb`mode))
```
url = "https://www.sogou.com/"
headers = { "User-Agent" : UA, }
# 动态更新的, 下次你再找这的时候可能你chrome版本又不一样了
response = requests.get(url, headers=headers) # 请求并获得相应对象
# response.encoding = 'utf-8'  # 可选调整编码方法
# response.apparent_encoding 获取推荐的编码 (比如有的lj网站中文不用utf编码用gbxxxx)
html = response.text
```
post
```
data = { "query" : "x", }
headers = { "User-Agent" : UA, }
response = requests.get(url, data,  headers=headers) # 请求并获得相应对象
```

status_code
`response.status_code`
200是ok, 或用 `requests.codes.ok`代替200这个常数

### 获取自己访问的Headers
```
# http://httpbin.org/get是个工具网站，直接返回请求头的信息 (可以用于测试自己伪装headers是否到位
url = 'http://httpbin.org/get'
print(requests.get(url).text)
```

例如, 不使用UA伪装时, UA会显示你用python request

### 使用session
```
s = requests.Session()
s.cookies = cookie
```

然后s就可以当个requests来用了

### 伪装(反"反爬")
#### UA伪装
80%左右的网站都用了UA检测, 所以这个伪装几乎是必须要的

随便开一个网页, 右键检查(或用F12), network里随便点一个包, 在里面信息里找到 User-Agent
```
UA = "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.105 Safari/537.36"
headers = { 'User-Agent': UA, }
response = requests.get(url, params, headers=headers)
```
